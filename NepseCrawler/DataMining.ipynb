{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import time\n",
    "import os.path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_listing = \"http://www.nepalstock.com.np/company?_limit=500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "http.addheaders = [('User-agent', 'Mozilla/61.0')]\n",
    "web_page = http.request('GET',company_listing)\n",
    "soup = BS(web_page.data, 'html5lib')\n",
    "table = soup.find('table')\n",
    "company=[]\n",
    "rows = [row.findAll('td') for row in table.findAll('tr')[1:-2]]\n",
    "col = 0\n",
    "notfirstrun = False\n",
    "for row in rows:\n",
    "    companydata =[]\n",
    "    for data in row:\n",
    "        if col == 5 and notfirstrun:\n",
    "            companydata.append(data.a.get('href').split('/')[-1])\n",
    "        else:\n",
    "            companydata.append(data.text.strip())\n",
    "        col += 1\n",
    "    company.append(companydata)\n",
    "    col =0\n",
    "    notfirstrun = True\n",
    "\n",
    "df = pd.DataFrame(company[1:],columns=company[0])\n",
    "df.rename(columns={'Operations':'Symbol No'},inplace=True)\n",
    "df.index.name = \"SN\"\n",
    "df.drop(columns='',inplace=True)\n",
    "df.drop(columns='S.N.',inplace=True)\n",
    "df.to_json('CompanyList.json',orient='index')\n",
    "print('There are %s Companies'%len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Company Details\n",
    "symbol = \"ADBL\"\n",
    "url = \"http://www.nepalstock.com/company/\"\n",
    "try:\n",
    "    req = requests.post(url, data={\"stock_symbol\":symbol}, verify=False)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(e)\n",
    "response = req.text\n",
    "soup = BS(response, \"lxml\")\n",
    "table = soup.find(\"table\")\n",
    "print (\"Company: \",table.findAll(\"td\")[0].string)\n",
    "for row in table.findAll(\"tr\")[4:]:\n",
    "    col = row.findAll(\"td\")\n",
    "    print (col[0].string,\": \",col[1].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily FloorSheet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DailyFloorSheet=\"http://www.nepalstock.com.np/main/floorsheet/index/0/?_limit=5000\"\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "http.addheaders = [('User-agent', 'Mozilla/61.0')]\n",
    "web_page = http.request('GET',DailyFloorSheet)\n",
    "soup = BS(web_page.data, 'html5lib')\n",
    "table = soup.find('table')\n",
    "FloorSheet=[]\n",
    "rows = [row.findAll('td') for row in table.findAll('tr')[1:-2]]\n",
    "for row in rows:\n",
    "    FloorSheet.append([data.text.strip() for data in row])\n",
    "FloorSheetdf = pd.DataFrame(FloorSheet[1:-1],columns=FloorSheet[0])\n",
    "FloorSheetdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(FloorSheetdf['Contract No'],format='%Y%m%d%H%M%f').dt.date\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CompanyStocks Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompanyStocksTransactions(SymbolNo,startDate):\n",
    "    url=\"http://www.nepalstock.com.np/company/transactions/%s/0/?startDate=%s&endDate=&_limit=9000000\"%(SymbolNo,startDate)\n",
    "    print(\"Connecting to %s \"%url)\n",
    "    http = urllib3.PoolManager()\n",
    "    http.addheaders = [('User-agent', 'Mozilla/61.0')]\n",
    "    web_page = http.request('GET',url)\n",
    "    print(\"Adding to DataFrame\")\n",
    "    soup = BS(web_page.data, 'html5lib')\n",
    "    table = soup.find('table')\n",
    "    FloorSheet=[]\n",
    "    rows = [row.findAll('td') for row in table.findAll('tr')[1:-2]]\n",
    "    for row in rows:\n",
    "        FloorSheet.append([data.text.strip() for data in row])\n",
    "    FloorSheetdf = pd.DataFrame(FloorSheet[1:],columns=FloorSheet[0])\n",
    "    FloorSheetdf['Date']=pd.to_datetime(dfNepse['Contract No'], format='%Y%m%d%H%M%f', errors='ignore')\n",
    "    return FloorSheetdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "startDate= '2001-1-1'\n",
    "count = 0\n",
    "for symbol in list(df['Symbol No']):\n",
    "    print(\"Stock No: %s\\nTime: %s\"%(symbol,time.ctime()))\n",
    "    filename = \"./data/NEPSE%s.csv\"%symbol\n",
    "    count +=1\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"Stock No: %s Data Already Downloaded\"%symbol)\n",
    "    else:\n",
    "        dftest=CompanyStocksTransactions(symbol,startDate)\n",
    "        dftest.to_csv(filename)\n",
    "    print(\"%s of %s completed \\n\"%(count,len(df['Symbol No'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# Need to convert Contract Number to Date-time\n",
    "Stock = 'EBL'\n",
    "symbol = \"%d\"%df[df['Stock Symbol']==Stock]['Symbol No']\n",
    "print(symbol)\n",
    "dfNepse=pd.read_csv(\"./data/NEPSE%s.csv\"%symbol)\n",
    "dfNepse.sort_values('Contract No',inplace = True)\n",
    "startfrom=200101016341249\n",
    "dfNepse=dfNepse[dfNepse['Contract No']>startfrom]\n",
    "dfNepse.plot(x='Contract No', y = 'Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNepse.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"NMB\"\n",
    "url = \"http://nepalstock.com/marketdepth/\"\n",
    "try:\n",
    "    req = requests.post(url, data={\"stock_symbol\":symbol}, verify=False)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(e)\n",
    "response = req.text\n",
    "soup = BS(response, \"lxml\")\n",
    "tables = soup.findAll(\"table\")\n",
    "for table in tables:\n",
    "    for row in table.findAll(\"tr\")[4:]:\n",
    "        col = row.findAll(\"td\")\n",
    "        print (col[0].string,\": \",col[1].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
